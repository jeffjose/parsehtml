#!/usr/bin/env python3

import sys
import argparse
from bs4 import BeautifulSoup
import requests
import fileinput
import simplejson as json

from  pygments import highlight
from pygments.lexers import PythonLexer
from pygments.formatters import TerminalTrueColorFormatter, Terminal256Formatter

parser = argparse.ArgumentParser(description = "Parse and filter HTML")

parser.add_argument('query', help = "CSS selector and filter expression", default = ":root", nargs = "?")
parser.add_argument('--input', help = "Input URL. Use - for stdin", default = "-")
parser.add_argument('--indent', help = "Indent", default = 2, type = int)

args = parser.parse_args()

def parseHTML(input):

    if input.startswith('http'):
        html = requests.get(input).text
    elif input is "-":
        html = sys.stdin.read()
    else:
        html = open(input, 'r').read()

    return html
parser.add_argument('input', help = "Input URL. Use - for stdin", default = "-")

def formatter(str):
    try:
        j = json.loads(str)
    except:
        return str
    else:
        return highlight(json.dumps(j, indent = args.indent), PythonLexer(), Terminal256Formatter(style = "autumn"))

def printer(tags, display):

    for tag in tags:

        if not display:
            print(tag.prettify(formatter = formatter), end = "")
        else:
            import pdb; pdb.set_trace()

def parseSelector(query):

    try:
        selector, display = query.split('|')
    except:
        selector = query
        display = ""

    return selector, display

html = parseHTML(args.input)

soup = BeautifulSoup(html, features = 'html.parser')

selector, display = parseSelector(args.query)
print(selector, display)

matches = soup.select(selector)

printer(matches, display)
